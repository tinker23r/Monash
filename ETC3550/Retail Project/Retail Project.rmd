---
title: "Retail Forecasting Project"
subtitle: "ETC3550"
author: "Chelaka Paranahewa"
output: 
  pdf_document:
    fig_crop: false
---
```{r setup, echo = FALSE, include = FALSE, warning=FALSE, error=FALSE}
library(fpp3, warn.conflicts = FALSE)
library(knitr, warn.conflicts = FALSE)
library(progressr, warn.conflicts = FALSE)
set.seed(31455034)
myseries <- aus_retail %>%
    # Remove discontinued series
    filter(!(`Series ID` %in% c(
        "A3349561R", "A3349883F", "A3349499L", "A3349902A",
        "A3349588R", "A3349763L", "A3349372C", "A3349450X",
        "A3349679W", "A3349378T", "A3349767W", "A3349451A"
    ))) %>%
    # Select a series at random
    filter(`Series ID` == sample(`Series ID`, 1))
```

# Statistical features of Australian Retail

```{r Original Dataset Table, echo = FALSE}
knitr::kable(
    head(myseries),
    caption = "A few rows of the dataset, Other Retailing in South Australia"
)
```

```{r Original Dataset Graph, echo = FALSE}
myseries %>% autoplot(Turnover) +
    labs(
        title = "Australia Retail Turnover",
        subtitle = "Original"
    ) +
    ylab("Turnover [million $AUD]")
```

<!-- Explain trends like variance -->
Plotting the original dataset, we can see a general trend upwards. The dataset also has a seasonal pattern which during the early 1980 - 1990, was relatively small compared to later years where the spike grows to large proportions. 

```{r Seasonal Plot of Dataset, echo = FALSE}
myseries %>%
    gg_season(Turnover, labels = "both") +
    labs(
        y = "Turnover [million $AUD]",
        title = "Seasonal Plot: Australia Retail Turnover"
    )
```

From the seasonal plot, there is a clear increase in retail sales during the month December which suggests that there is strong seasonality with the data. 

# Transformations and Differencings

### ETS Modelling

To prepare the dataset for ETS modelling, the data needs to be tranformed so that the variance across the dataset remains relatively constant. As mentioned before the original dataset does not have a constant seasonal variation, since the beginning has small peaks in the seasonal variation which gradually grow over the course of approximately two decades. 

To stabalise the seasonal variation, a Box-Cox transformation can be use. A Box-Cox transformation needs a value for $\lambda$ to transformed the date. A $\lambda = 0$ will perform a logrithmic tranformation to the data, whereas $\lambda \ne 0$ will perform a exponential transformation. 

```{r, echo=FALSE, eval=FALSE}
# Natural Log
myseries %>% autoplot(box_cox(Turnover, 0.0)) +
    labs(
        title = "Australia Retail Turnover",
        subtitle = "Box-Cox transformed (Natural Log)"
    ) +
    ylab("Turnover [million $AUD]")
```

```{r Transforming Dataset and Graph for ETS Models}
ets_lambda <- myseries %>%
    features(Turnover, features = guerrero) %>%
    pull(lambda_guerrero)

myseries %>% autoplot(box_cox(Turnover, ets_lambda)) +
    labs(
        title = "Australia Retail Turnover",
        subtitle = "Box-Cox transformed (Guerrero's method)"
    ) +
    ylab("Turnover [million $AUD]")
```

Using a $\lambda$ value close to 0 such as `r ets_lambda` gives the best transformation that keeps the seasonal variations constant through out the time series. This value was determined by using Guerreor's method and then manually checking values around it to verify its the best value for $\lambda$. 

### ARIMA Modelling

To objectively determine if the dataset needs differencing we will use unitroot_kpss, unitroot_ndiffs & unitroot_nsdiffs. 
```{r KPSS}
myseries %>%
    features(Turnover, unitroot_kpss) %>%
    kable(caption = "Kwiatkowski-Phillips-Schmidt-Shin Test")
```
The KPSS testis performing a hypothesis test to verify that the data is stationary. However, the null hypothesis is rejected since the kpss_pvalue is less than 0.05, hence indicating that the data is not stationary and needs differencing to make it stationary.


```{r ndiffs}
myseries %>%
    features(Turnover, unitroot_ndiffs) %>%
    kable(caption = "Number of differences required for a stationary series")
```
```{r nsdiffs}
myseries %>%
    features(Turnover, unitroot_nsdiffs) %>%
    kable(caption = "Number of seasonal differences required for a stationary series")
```















# Modelling ARIMA and ETS models

```{r TSCV Training}
training <- myseries %>%
    filter(
        Month < yearmonth("2017 Jan"),
        Month >= yearmonth("1983 Jan")
    ) %>%
    stretch_tsibble(.init = 12, .step = 12) %>%
    relocate(State, Industry, `Series ID`, .id)

progressr::with_progress(
    TSCV_model <- training %>%
        model(
            Original = ETS(Turnover ~ error("M") + trend("A") + season("M")),
            Transformed = ETS(
                box_cox(Turnover, ets_lambda) ~ error("M") + trend("A") +
                    season("M")
            )
        )
)
```

```{r ARIMA STUFF}
training %>%
    mutate(diff_turnover = difference(Turnover, differences = 2)) %>%
    features(diff_turnover, ljung_box, lag = 12)

myseries %>% autoplot(
    difference(
        box_cox(Turnover, ets_lambda),
        differences = 2
    )
)
myseries %>%
    ACF(difference(box_cox(Turnover, ets_lambda), differences = 2)) %>%
    autoplot()
```
```{r Reporting on TSCV Model}
# TSCV Accuracy
TSCV_model %>%
    forecast(h = 24) %>%
    accuracy(myseries)

# Training Set Accuracy
# TSCV_model %>%
#     glance()
TSCV_model %>%
    glance() %>%
    arrange(.model) %>%
    view()
```

```{r}
progressr::with_progress(
    myseries %>% model(
        auto = ARIMA(Turnover, stepwise = FALSE, approximation = FALSE),
        manual = ARIMA(Turnover ~ pdq(1, 0, 1) + PDQ(2, 1, 2))
    )
)
```