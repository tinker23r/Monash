---
title: "Retail Forecasting Project"
subtitle: "ETC3550"
author: "Chelaka Paranahewa"
output: 
  pdf_document:
    fig_crop: false
---
# TODO
- Write analysis for Diagnostics

```{r setup, echo = FALSE, include = FALSE, warning=FALSE, error=FALSE}
library(fpp3, warn.conflicts = FALSE)
library(knitr, warn.conflicts = FALSE)
library(progressr, warn.conflicts = FALSE)
set.seed(31455034)
myseries <- aus_retail %>%
    # Remove discontinued series
    filter(!(`Series ID` %in% c(
        "A3349561R", "A3349883F", "A3349499L", "A3349902A",
        "A3349588R", "A3349763L", "A3349372C", "A3349450X",
        "A3349679W", "A3349378T", "A3349767W", "A3349451A"
    ))) %>%
    # Select a series at random
    filter(`Series ID` == sample(`Series ID`, 1))
```

# Statistical features of Australian Retail

```{r Original Dataset Table, echo = FALSE}
knitr::kable(
    head(myseries),
    caption = "A few rows of the dataset, Other Retailing in South Australia"
)
```

```{r Original Dataset Graph, echo = FALSE}
myseries %>% autoplot(Turnover) +
    labs(
        title = "Australia Retail Turnover",
        subtitle = "Original"
    ) +
    ylab("Turnover [million $AUD]")
```

<!-- Explain trends like variance -->
Plotting the original dataset, we can see a general trend upwards. The dataset also has a seasonal pattern which during the early 1980 - 1990, was relatively small compared to later years where the spike grows to large proportions. 

```{r Seasonal Plot of Dataset, echo = FALSE}
myseries %>%
    gg_season(Turnover, labels = "both") +
    labs(
        y = "Turnover [million $AUD]",
        title = "Seasonal Plot: Australia Retail Turnover"
    )
```

From the seasonal plot, there is a clear increase in retail sales during the month December which suggests that there is strong seasonality with the data. 

# Transformations and Differencings


### Transformations

To prepare the dataset for ARIMA modelling, the data needs to be tranformed so that the variance across the dataset remains relatively constant. As mentioned before the original dataset does not have a constant seasonal variation, since the beginning has small peaks in the seasonal variation which gradually grow over the course of approximately two decades. 

To stabalise the seasonal variation, a Box-Cox transformation can be use. A Box-Cox transformation needs a value for $\lambda$ to transformed the date. A $\lambda = 0$ will perform a logrithmic tranformation to the data, whereas $\lambda \ne 0$ will perform a exponential transformation. 

```{r, echo=FALSE, eval=FALSE}
# Natural Log
myseries %>% autoplot(box_cox(Turnover, 0.0)) +
    labs(
        title = "Australia Retail Turnover",
        subtitle = "Box-Cox transformed (Natural Log)"
    ) +
    ylab("Turnover [million $AUD]")
```

```{r Transforming Dataset and Graph for ETS Models}
lambda <- myseries %>%
    features(Turnover, features = guerrero) %>%
    pull(lambda_guerrero)

myseries %>% autoplot(box_cox(Turnover, lambda)) +
    labs(
        title = "Australia Retail Turnover",
        subtitle = "Box-Cox transformed (Guerrero's method)"
    ) +
    ylab("Turnover [million $AUD]")
```

Using a $\lambda$ value close to 0 such as `r lambda` gives the best transformation that keeps the seasonal variations constant through out the time series. This value was determined by using Guerreor's method and then manually checking values around it to verify its the best value for $\lambda$. 

### Differencing

To objectively determine if the dataset needs differencing we will use unitroot_kpss & unitroot_nsdiffs. 
```{r KPSS}
myseries %>%
    features(Turnover, unitroot_kpss) %>%
    kable(caption = "Kwiatkowski-Phillips-Schmidt-Shin Test")

myseries %>%
    features(difference(Turnover, 12), unitroot_kpss) %>%
    kable(caption = "Kwiatkowski-Phillips-Schmidt-Shin Test")
```

The KPSS testis performing a hypothesis test to verify that the data is stationary. However, the null hypothesis is rejected since the kpss_pvalue is less than 0.05, hence indicating that the data is not stationary and needs differencing to make it stationary.

After a first order differencing, the hypothesis test gives a p value of 0.10 which is greater than 0.05 which means the null hypothesis is not rejected. Thus making the first difference of the dataset, stationary. 

Based on Kwiatkowski-Phillips-Schmidt-Shin's Test, we have determined that the data needs differencing to make it stationary, while we tested with a first stage differencing we need to verify this using the unitroot_ndiffs which reveals the number of differencing that is needed. 

```{r Num of Diffs}
myseries %>%
    features(box_cox(Turnover, lambda), unitroot_ndiffs) %>%
    kable(caption = "Number of differences required for a stationary series")
```

According to unitroot_ndiffs the data only needs to perform a first stage differencing. 

```{r Num of Seasonal Diffs}
myseries %>%
    features(box_cox(Turnover, lambda), unitroot_nsdiffs) %>%
    kable(
        caption =
            "Number of seasonal differences required for a stationary series"
    )
```

According to unitroot_ndiffs the data only needs to perform a first stage seasonal differencing. 


# Modelling ARIMA and ETS models

```{r Creating Training Data, echo=FALSE}
training <- myseries %>%
    filter(Month < yearmonth("2017 Jan"))
```

### ETS Modelling

For the ETS models, the best method to short list possible candidate models is to use the AIC values that are outputed after models are trained. AIC, otherwise known as Akaike's Information Criterion, is defined as $AIC = T \log (\frac {SSE} {T}) + 2(k+2)$. Using it to find a model by minimising the AIC will result in a model that is good at forecasting. 

To find the model with the lowest AIC value, we need to check all the different models which can be done by `model(ETS(Turnover))` or manually testing all combinations. 

```{r TSCV Training Short Listing}
progressr::with_progress(
    trained_etsmodel <- training %>%
        model(
            # Additive
            ANN =  ETS(Turnover ~ error("A") + trend("N") + season("N")),
            ANA =  ETS(Turnover ~ error("A") + trend("N") + season("A")),
            ANM =  ETS(Turnover ~ error("A") + trend("N") + season("M")),
            AAN =  ETS(Turnover ~ error("A") + trend("A") + season("N")),
            AAA =  ETS(Turnover ~ error("A") + trend("A") + season("A")),
            AAM =  ETS(Turnover ~ error("A") + trend("A") + season("M")),
            AAdN = ETS(Turnover ~ error("A") + trend("Ad") + season("N")),
            AAdA = ETS(Turnover ~ error("A") + trend("Ad") + season("A")),
            AAdM = ETS(Turnover ~ error("A") + trend("Ad") + season("M")),

            # Multiplicative
            MNN =  ETS(Turnover ~ error("M") + trend("N") + season("N")),
            MNA =  ETS(Turnover ~ error("M") + trend("N") + season("A")),
            MNM =  ETS(Turnover ~ error("M") + trend("N") + season("M")),
            MAN =  ETS(Turnover ~ error("M") + trend("A") + season("N")),
            MAA =  ETS(Turnover ~ error("M") + trend("A") + season("A")),
            MAM =  ETS(Turnover ~ error("M") + trend("A") + season("M")), #*
            MAdN = ETS(Turnover ~ error("M") + trend("Ad") + season("N")),
            MAdA = ETS(Turnover ~ error("M") + trend("Ad") + season("A")),
            MAdM = ETS(Turnover ~ error("M") + trend("Ad") + season("M"))
        )
)

trained_etsmodel %>%
    glance() %>%
    select(.model, AIC, AICc) %>%
    arrange(AIC) %>%
    kable(caption = "ETS Models ranked based on AIC")
```

```{r Top six ets models, echo=FALSE}
top_ets <- trained_etsmodel %>%
    glance() %>%
    select(.model, AIC, AICc) %>%
    arrange(AIC) %>%
    head() %>%
    pull(.model)
```

By testing all combinations we see that the top 6 ETS models are: `r top_ets`. The list of ETS models can be further reduced by plotting a time series decomposition which shows the relationship between the seasonality and error components. 

```{r SLT Decomposition}
training %>%
    model(STL(
        box_cox(Turnover, lambda) ~
            trend(window = 13) + season(window = "periodic"),
        robust = TRUE
    )) %>%
    components() %>%
    autoplot()
```

The decomposition shown in the graph indicates that the time series is multiplicative. Since the transformation done to the dataset was a box_cox transformation using a lambda value of `r lambda` which is closer to 0. And according to the box_cox transofrmation lambda value being zero is a log transformation. Hence the multiplicative decomposition.

So it can be deduced that the time series has a multiplicative relationship both the seasonality and error components which means the final short list of ETS models are: MNM, MAM, MAdM.

```{r TSCV Training, echo=FALSE}
progressr::with_progress(
    trained_etsmodel <- training %>%
        model(
            MNM = ETS(Turnover ~ error("M") + trend("N") + season("M")),
            MAM = ETS(Turnover ~ error("M") + trend("A") + season("M")), #*
            MAdM = ETS(Turnover ~ error("M") + trend("Ad") + season("M"))
        )
)
```

```{r Best ETS model identifier, echo=FALSE}
ets <- trained_etsmodel %>%
    select(mable_vars(trained_etsmodel)) %>%
    glance()
index <- ets$AIC %>% which.min()
```
After short listing, the best ETS model according to the AIC values is a `r ets[[index, ".model"]]` with a AIC value of `r ets[[index, "AICc"]]`

```{r Accuracy of ETS models}
bind_rows(
    trained_etsmodel %>%
        accuracy(),
    trained_etsmodel %>%
        forecast(h = "2 years") %>%
        accuracy(myseries)
) %>%
    arrange(MASE) %>%
    select(-State, -Industry, -ME, -MPE, -ACF1) %>%
    kable(caption = "Shortlist of the best ETS Models ranked on MASE")
```

After testing the models with the last 2 years of the dataset, the MNM model proves to be the best across RMSE, MAPE and MASE. The MAM and MAdM are also just as good with both tied for second place since their RMSE, MAPE and MASE values are marginally different. 

### ARIMA Modelling

From section Transformations and Differencings, we know that the dataset needs to transformed and differenced once to make the data stationary. So we can directly plot the ACF and PACF plots of the stationary dataset.

```{r ACF and PACF Plots, warning = FALSE}
training %>% gg_tsdisplay(
    difference(box_cox(Turnover, lambda), 12),
    plot_type = "partial", lag = 64
) + labs(title = "ACF and PACF plots of transformed and differenced Turnover")
```

The ACF plot shows a decaying sinusoidal pattern and by looking at the PACF the last  siginificant lag is at lag 3  which may suggest a non-seasonal AR(3).

There is exponential decay in the seasonal lags of the PACF which could indicate a seasonal MA(3) component. 

From the ACF and PACF plots we have a possible ARIMA model to start from ARIMA(box_cox(Turnover, lambda) ~ 1 + pdq(3, 0, 0) + PDQ(0, 1, 3))

To get better values we could make the p, P, q & Q values drift by 1 value and also checking with the addition of a constant.

```{r ARIMA Short Listing}
progressr::with_progress(
    trained_arimamodel <- training %>% model(
        # search = ARIMA(box_cox(Turnover, lambda), stepwise = FALSE),
        # stepwise = ARIMA(box_cox(Turnover, lambda)),
        ARIMA1300013 = ARIMA(box_cox(Turnover, lambda) ~ 1 + pdq(3, 0, 0) + PDQ(0, 1, 3)),
        ARIMA0300013 = ARIMA(box_cox(Turnover, lambda) ~ 0 + pdq(3, 0, 0) + PDQ(0, 1, 3)),
        ARIMA1200013 = ARIMA(box_cox(Turnover, lambda) ~ 1 + pdq(2, 0, 0) + PDQ(0, 1, 3)),
        ARIMA0200013 = ARIMA(box_cox(Turnover, lambda) ~ 0 + pdq(2, 0, 0) + PDQ(0, 1, 3)),
        ARIMA1201013 = ARIMA(box_cox(Turnover, lambda) ~ 1 + pdq(2, 0, 1) + PDQ(0, 1, 3)),
        ARIMA0201013 = ARIMA(box_cox(Turnover, lambda) ~ 0 + pdq(2, 0, 1) + PDQ(0, 1, 3)),
        ARIMA1300112 = ARIMA(box_cox(Turnover, lambda) ~ 1 + pdq(3, 0, 0) + PDQ(1, 1, 2)),
        ARIMA0300112 = ARIMA(box_cox(Turnover, lambda) ~ 0 + pdq(3, 0, 0) + PDQ(1, 1, 2)),
        ARIMA1200112 = ARIMA(box_cox(Turnover, lambda) ~ 1 + pdq(2, 0, 0) + PDQ(1, 1, 2)),
        ARIMA0200112 = ARIMA(box_cox(Turnover, lambda) ~ 0 + pdq(2, 0, 0) + PDQ(1, 1, 2))
    )
)

trained_arimamodel %>%
    glance() %>%
    select(.model, AIC, AICc) %>%
    arrange(AIC) %>%
    kable(caption = "ARIMA Models ranked based on AIC")
```

```{r, echo=FALSE, eval=FALSE}
# TESTING ONLY
progressr::with_progress(
    trained_arimamodel <- training %>% model(
        manual1 = ARIMA(box_cox(Turnover, lambda) ~ pdq(0, 1, 1) + PDQ(2, 1, 2)), # nolint
        manual2 = ARIMA(box_cox(Turnover, lambda) ~ pdq(0, 1, 2) + PDQ(2, 1, 2)), # nolint
        manual3 = ARIMA(box_cox(Turnover, lambda) ~ pdq(1, 1, 1) + PDQ(2, 1, 2)), # nolint

        manual4 = ARIMA(box_cox(Turnover, lambda) ~ pdq(2, 1, 0) + PDQ(0, 1, 1)), # nolint
        manual5 = ARIMA(box_cox(Turnover, lambda) ~ pdq(2, 1, 0) + PDQ(1, 1, 0)), # nolint
        manual6 = ARIMA(box_cox(Turnover, lambda) ~ pdq(0, 1, 1) + PDQ(0, 1, 1)), # nolint
        manual7 = ARIMA(box_cox(Turnover, lambda) ~ pdq(0, 1, 1) + PDQ(1, 1, 0)), # nolint
    )
)
```

By checking slightly different variations of the initially obtained ARIMA model we can tell that they are fit the date well since their AIC values are close together.

```{r Accuracy of ARIMA models}
bind_rows(
    trained_arimamodel %>%
        accuracy(),
    trained_arimamodel %>%
        forecast(h = "2 years") %>%
        accuracy(myseries)
) %>%
    arrange(MASE) %>%
    select(-State, -Industry, -ME, -MPE, -ACF1) %>%
    kable(caption = "Shortlist of the best ARIMA Models ranked on MASE")
```

After testing the models with the last 2 years of the dataset, the manualXv2 models performed the best during the testing phase. 

# Best Models for Forecasting

### Best ETS Model

```{r MNM Parameters}
MNM <- trained_etsmodel %>%
    select(MNM)


MNM %>%
    report()
```


```{r MNM Diagnostic}
MNM %>%
    gg_tsresiduals() + labs(title = "ETS Innotvation Residuals Plot")

MNM %>%
    augment() %>%
    features(.innov, ljung_box, lag = 24, dof = 14)
```

```{r}
MNM_fc <- MNM %>%
    forecast(h = "2 years")

# MNM %>%
    # kable(caption = "")

MNM_fc %>%
    hilo(level = c(80, 95)) %>%
    select(-.model, -Turnover) %>%
    kable(caption = "ETS Point Forecast and Point Interval (80% & 95%)")
```

### Best ARIMA Model

```{r ARIMA1200013 Parameters}
ARIMA1200013 <- trained_arimamodel %>%
    select(ARIMA1200013)
    
ARIMA1200013 %>%
    report()
```

```{r ARIMA1200013 Diagnostic}
ARIMA1200013 %>%
    gg_tsresiduals() + labs(title = "ARIMA Innotvation Residuals Plot")

ARIMA1200013 %>%
    augment() %>%
    features(.innov, ljung_box, lag = 12, dof = 5)
```

```{r}
ARIMA1200013_fc <- ARIMA1200013 %>%
    forecast(h = "2 years")

# ARIMA1200013_fc %>% kable(caption = "")

ARIMA1200013_fc %>%
    hilo(level = c(80, 95)) %>%
    select(-.model, -Turnover) %>%
    kable(caption = "ARIMA Point Forecast and Point Interval (80% & 95%)")
```